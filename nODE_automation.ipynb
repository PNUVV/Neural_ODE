{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint\n",
    "from prettytable import PrettyTable\n",
    "from torch import nn\n",
    "import os\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.702250300Z",
     "start_time": "2023-08-15T16:04:51.676004Z"
    }
   },
   "id": "a361c462737286f3"
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "def train_ode_model(x_data, t_data, hidden_dim,num_layers, learning_rate, epochs):\n",
    "    # Neural ODE Model Definition\n",
    "    class ODEFunc(nn.Module):\n",
    "        def __init__(self, class_num_layers, class_hidden_dim):\n",
    "            super(ODEFunc, self).__init__()\n",
    "            layers = []\n",
    "            layers.append(nn.Linear(2, class_hidden_dim))\n",
    "            for _ in range(class_num_layers):\n",
    "                layers.append(nn.ELU())\n",
    "                layers.append(nn.Linear(class_hidden_dim, class_hidden_dim))\n",
    "            layers.append(nn.ELU())\n",
    "            layers.append(nn.Linear(class_hidden_dim, 2))\n",
    "            self.net = nn.Sequential(*layers)\n",
    "            self.nfe = 0\n",
    "    \n",
    "        def forward(self, t, x):\n",
    "            self.nfe += 1\n",
    "            return self.net(x)\n",
    "\n",
    "\n",
    "    func = ODEFunc(num_layers,hidden_dim)\n",
    "    optimizer = torch.optim.Adam(func.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training Loop\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        x_pred = odeint(func, x_data[0], t_data).squeeze()\n",
    "        loss = criterion(x_pred, x_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return func, losses\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.704264900Z",
     "start_time": "2023-08-15T16:04:51.683389500Z"
    }
   },
   "id": "2fe85dbb7b6d0a4d"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_and_save_graph(x_data, x_pred, title, save_path):\n",
    "    \"\"\"\n",
    "    Plot the true and predicted trajectory and save the plot to a file.\n",
    "\n",
    "    :param x_data: Ground truth data\n",
    "    :param x_pred: Predicted data\n",
    "    :param title: Title of the plot\n",
    "    :param save_path: Path to save the plot\n",
    "    \"\"\"\n",
    "    plt.plot(x_data[:, 0].detach().numpy(), x_data[:, 1].detach().numpy(), label='True trajectory')\n",
    "    plt.plot(x_pred[:, 0].detach().numpy(), x_pred[:, 1].detach().numpy(), label='Predicted trajectory')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close() # Close the plot to avoid displaying it in the notebook\n",
    "\n",
    "# This function will also be used inside the \"train_ode_models\" function.    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.761875Z",
     "start_time": "2023-08-15T16:04:51.699718900Z"
    }
   },
   "id": "3b94b60aa4a68b0d"
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def numerical_validation(x_data, x_pred):\n",
    "    \"\"\"\n",
    "    Perform numerical validation on the predicted data.\n",
    "\n",
    "    :param x_data: Ground truth data\n",
    "    :param x_pred: Predicted data\n",
    "    :return: r_squared, mean_abs_rel_residual, max_abs_rel_residual\n",
    "    \"\"\"\n",
    "    slope, intercept, r_value, _, _ = linregress(x_data.flatten().detach().numpy(), x_pred.flatten().detach().numpy())\n",
    "    r_squared = r_value**2\n",
    "    mean_abs_rel_residual = mean_absolute_error(x_data.detach().numpy(), x_pred.detach().numpy()) / (x_data.abs().mean())\n",
    "    max_abs_rel_residual = max(np.max(np.abs(x_data.detach().numpy() - x_pred.detach().numpy()), axis=0) / x_data.abs().max())\n",
    "    \n",
    "    return r_squared, mean_abs_rel_residual, max_abs_rel_residual\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.764368200Z",
     "start_time": "2023-08-15T16:04:51.711153600Z"
    }
   },
   "id": "c2b8ddca905a864d"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "from pyDOE import lhs\n",
    "import torch\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "def train_ode_models(n_samples, hidden_dim,num_layers, learning_rate, epochs, save_path):\n",
    "    \"\"\"\n",
    "    Train ODE models for different epochs and save the results.\n",
    "\n",
    "    :param n_samples: Number of samples\n",
    "    :param hidden_dim: Hidden dimension size\n",
    "    :param learning_rate: Learning rate\n",
    "    :param epochs_list: List of epochs for training\n",
    "    :param save_path: Path to save the results\n",
    "    :return: best_func, x_train, t_train, x_test, t_test, max_r_squared_model\n",
    "    \"\"\"\n",
    "    # Latin Hypercube Design (LHD) sample generation\n",
    "    lhd_samples = lhs(2, samples=n_samples)\n",
    "    t_lhd = torch.tensor(np.sort(lhd_samples[:, 0]) * 2 * np.pi, dtype=torch.float32)\n",
    "    x_lhd = torch.cat((torch.sin(t_lhd).reshape(-1, 1), torch.cos(t_lhd).reshape(-1, 1)), dim=1)\n",
    "\n",
    "    # Data splitting\n",
    "    train_size = int(0.7 * len(x_lhd))\n",
    "    val_size = int(0.15 * len(x_lhd))\n",
    "    \n",
    "    x_train = x_lhd[:train_size]\n",
    "    t_train = t_lhd[:train_size]\n",
    "    \n",
    "    x_val = x_lhd[train_size:train_size + val_size]\n",
    "    t_val = t_lhd[train_size:train_size + val_size]\n",
    "    \n",
    "    x_test = x_lhd[train_size + val_size:]\n",
    "    t_test = t_lhd[train_size + val_size:]\n",
    "\n",
    "    best_func = None\n",
    "    best_r_squared = -float('inf') # Initialize with negative infinity\n",
    "    validation_results = pd.DataFrame(columns=['Epochs', 'Hidden_Dim', 'Samples', 'Data_Type', 'R_Squared', 'Mean_Abs_Rel_Residual', 'Max_Abs_Rel_Residual'])\n",
    "\n",
    "    # Model selection and result saving logic\n",
    "    for idx in range(5):\n",
    "        func, losses = train_ode_model(x_train, t_train, hidden_dim,num_layers, learning_rate, epochs) # Function to be defined\n",
    "\n",
    "        x_pred_val = odeint(func, x_val[0], t_val).squeeze() # odeint to be defined\n",
    "        r_squared, mean_abs_rel_residual, max_abs_rel_residual = numerical_validation(x_val, x_pred_val)\n",
    "\n",
    "        # Save validation results\n",
    "        validation_results.loc[idx] = [epochs, hidden_dim, n_samples, 'Validation', r_squared, mean_abs_rel_residual, max_abs_rel_residual]\n",
    "\n",
    "        # Select best model\n",
    "        if r_squared > best_r_squared:\n",
    "            best_r_squared = r_squared\n",
    "            best_func = copy.deepcopy(func)\n",
    "\n",
    "    # Save CSV\n",
    "    validation_results.to_csv(f\"{save_path}/validation_results_{hidden_dim}_{n_samples}.csv\", index=False)\n",
    "    max_r_squared_model = validation_results['R_Squared'].idxmax()\n",
    "\n",
    "    return best_func, x_train, t_train, x_test, t_test, max_r_squared_model\n",
    "\n",
    "# The functions \"train_ode_model\" and \"odeint\" are to be defined as per the user's ODE model and training procedure.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.764368200Z",
     "start_time": "2023-08-15T16:04:51.729916900Z"
    }
   },
   "id": "345e0aa76549ce89"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "def save_results(x_pred, x_data, data_type, epochs, hidden_dim, n_samples, save_path):\n",
    "    # Plot the true trajectory and Neural ODE approximation\n",
    "    plt.plot(x_data[:, 0].detach().numpy(), x_data[:, 1].detach().numpy(), label='True trajectory')\n",
    "    plt.plot(x_pred[:, 0].detach().numpy(), x_pred[:, 1].detach().numpy(), label='Neural ODE approximation')\n",
    "    plt.legend()\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.title('2D Motion')\n",
    "    plt.savefig(f\"{save_path}/{data_type}_2D_Motion_epochs_{epochs}_hidden_{hidden_dim}_samples_{n_samples}.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Numerical Validation\n",
    "    slope, intercept, r_value, _, _ = linregress(x_data.flatten().detach().numpy(), x_pred.flatten().detach().numpy())\n",
    "    r_squared = r_value**2\n",
    "    mean_abs_rel_residual = mean_absolute_error(x_data.detach().numpy(), x_pred.detach().numpy()) / (x_data.abs().mean())\n",
    "    max_abs_rel_residual = max(np.max(np.abs(x_data.detach().numpy() - x_pred.detach().numpy()), axis=0) / x_data.abs().max())\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Metric\", \"Value\"]\n",
    "    table.add_row([\"Squared correlation coefficient (r^2)\", r_squared])\n",
    "    table.add_row([\"Mean absolute relative residual\", mean_abs_rel_residual])\n",
    "    table.add_row([\"Maximum of absolute relative residuals\", max_abs_rel_residual])\n",
    "    print(table)\n",
    "    \n",
    "    # Save numerical validation\n",
    "    with open(f\"{save_path}/{data_type}_numerical_validation_epochs_{epochs}_hidden_{hidden_dim}_samples_{n_samples}.txt\", \"w\") as file:\n",
    "        file.write(str(table))\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.764368200Z",
     "start_time": "2023-08-15T16:04:51.737443100Z"
    }
   },
   "id": "9f54fe4b39113496"
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def save_loss_and_validation(losses, validation_results, save_path, hidden_dim,n_samples,idx):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax1.plot(losses)\n",
    "    ax1.set_title('Training Loss (MSE)')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax2.plot(validation_results['Epochs'], validation_results['R_Squared'])\n",
    "    ax2.set_title('R_Squared Validation')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('R_Squared')\n",
    "    plt.savefig(f\"{save_path}/loss_and_validation_{hidden_dim}_{n_samples}_{idx}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def save_2d_and_actual_vs_predicted(x_data, x_pred, data_type, hidden_dim, n_samples, epochs, save_path):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # 2D Motion Plot\n",
    "    ax1.plot(x_data[:, 0].detach().numpy(), x_data[:, 1].detach().numpy(), label='True trajectory')\n",
    "    ax1.plot(x_pred[:, 0].detach().numpy(), x_pred[:, 1].detach().numpy(), label='Neural ODE approximation')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel('X Position')\n",
    "    ax1.set_ylabel('Y Position')\n",
    "    ax1.set_title('2D Motion')\n",
    "\n",
    "    # Actual vs Predicted Plot\n",
    "    ax2.scatter(x_data[:, 0].detach().numpy(), x_pred[:, 0].detach().numpy(), label='X Position')\n",
    "    ax2.scatter(x_data[:, 1].detach().numpy(), x_pred[:, 1].detach().numpy(), label='Y Position')\n",
    "    ax2.set_xlabel('Actual')\n",
    "    ax2.set_ylabel('Predicted')\n",
    "    ax2.legend()\n",
    "    ax2.set_title('Actual vs Predicted Plot')\n",
    "\n",
    "    file_suffix = f\"{data_type}_hidden_dim_{hidden_dim}_samples_{n_samples}_epochs_{epochs}\"\n",
    "    plt.savefig(f\"{save_path}/{file_suffix}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def return_numerical_validation(x_data, x_pred, data_type, hidden_dim, n_samples, epochs, save_path):\n",
    "    slope, intercept, r_value, _, _ = linregress(x_data.flatten().detach().numpy(), x_pred.flatten().detach().numpy())\n",
    "    r_squared = r_value**2\n",
    "    mean_abs_rel_residual = mean_absolute_error(x_data.detach().numpy(), x_pred.detach().numpy()) / (x_data.abs().mean())\n",
    "    max_abs_rel_residual = max(np.max(np.abs(x_data.detach().numpy() - x_pred.detach().numpy()), axis=0) / x_data.abs().max())\n",
    "\n",
    "    return r_squared, mean_abs_rel_residual, max_abs_rel_residual   \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.802216500Z",
     "start_time": "2023-08-15T16:04:51.768574Z"
    }
   },
   "id": "fd33a93a36744cb6"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "def ensure_list(*values):\n",
    "    max_length = max(len(value) if isinstance(value, list) else 1 for value in values)\n",
    "    return [[value] * max_length if not isinstance(value, list) else value * (max_length // len(value)) for value in values]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.831552300Z",
     "start_time": "2023-08-15T16:04:51.783048600Z"
    }
   },
   "id": "ec90575afbd2b7e4"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_2d_radius_difference_contour_fixed(x_data, x_pred, data_type, hidden_dim, n_samples, epochs, save_path):\n",
    "    # Calculate the radius for actual and predicted data\n",
    "    actual_radius = torch.sqrt(x_data[:, 0]**2 + x_data[:, 1]**2)\n",
    "    pred_radius = torch.sqrt(x_pred[:, 0]**2 + x_pred[:, 1]**2)\n",
    "\n",
    "    # Calculate the difference in radius\n",
    "    radius_difference = actual_radius - pred_radius\n",
    "\n",
    "    # Create a grid for contour plot\n",
    "    xx, yy = torch.meshgrid(torch.linspace(x_data[:, 0].min(), x_data[:, 0].max(), 30),\n",
    "                            torch.linspace(x_data[:, 1].min(), x_data[:, 1].max(), 30))\n",
    "    \n",
    "    # Interpolate radius_difference on the grid using detached numpy arrays\n",
    "    from scipy.interpolate import griddata\n",
    "    zz = griddata((x_data[:, 0].detach().numpy(), x_data[:, 1].detach().numpy()), radius_difference.detach().numpy(), (xx.numpy(), yy.numpy()), method='linear')\n",
    "\n",
    "    # Plotting the contour of radius difference\n",
    "    plt.contourf(xx.numpy(), yy.numpy(), zz, levels=20, cmap=\"viridis\")\n",
    "\n",
    "    # Plotting the actual vs predicted data\n",
    "    plt.plot(x_data[:, 0].detach().numpy(), x_data[:, 1].detach().numpy(), label='True trajectory')\n",
    "    plt.plot(x_pred[:, 0].detach().numpy(), x_pred[:, 1].detach().numpy(), label=f'{data_type} trajectory')\n",
    "    plt.legend()\n",
    "    plt.title(f'2D Motion Radius Difference Contour\\nHidden Dim: {hidden_dim}, Samples: {n_samples}, Epochs: {epochs}')\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "\n",
    "    # Saving the plot\n",
    "    plot_path = os.path.join(save_path, f'{data_type}_radius_difference_contour.png')\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close() # Close the plot to avoid displaying it in the notebook\n",
    "\n",
    "# You can replace the original function call with this one in your existing code\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.831552300Z",
     "start_time": "2023-08-15T16:04:51.795519900Z"
    }
   },
   "id": "c0673aab4d7ec239"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def plot_radius_deviation_histogram(x_data, x_pred, data_type, hidden_dim, n_samples, epochs, save_path):\n",
    "    # Calculate the radius for actual and predicted data\n",
    "    actual_radius = torch.sqrt(x_data[:, 0]**2 + x_data[:, 1]**2)\n",
    "    pred_radius = torch.sqrt(x_pred[:, 0]**2 + x_pred[:, 1]**2)\n",
    "\n",
    "    # Calculate the difference in radius (deviation)\n",
    "    radius_deviation = actual_radius - pred_radius\n",
    "\n",
    "    # Plotting the histogram of the radius deviation\n",
    "    plt.hist(radius_deviation.detach().numpy(), bins=20, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "    plt.title(f'Radius Deviation Histogram\\nHidden Dim: {hidden_dim}, Samples: {n_samples}, Epochs: {epochs}')\n",
    "    plt.xlabel('Radius Deviation')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Calculate and display mean and standard deviation\n",
    "    mean_deviation = radius_deviation.mean().item()\n",
    "    std_deviation = radius_deviation.std().item()\n",
    "    plt.axvline(mean_deviation, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_deviation:.2f}\\nStd Dev: {std_deviation:.2f}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Saving the plot\n",
    "    plot_path = os.path.join(save_path, f'{data_type}_radius_deviation_histogram.png')\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close() # Close the plot to avoid displaying it in the notebook\n",
    "\n",
    "# You can use this function in your existing code to visualize the distribution of radius deviation between actual and predicted trajectory\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:04:51.833069900Z",
     "start_time": "2023-08-15T16:04:51.811021500Z"
    }
   },
   "id": "331e33b4ecfc1f91"
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with n_samples=100, hidden_dim=32, learning_rate=0.001, epochs=100\n"
     ]
    }
   ],
   "source": [
    "# 0816 01:26 버전\n",
    "n_samples = 100\n",
    "# 절대 정수로 넣어주세요\n",
    "num_layers = 4\n",
    "hidden_dim = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "\n",
    "n_samples_list, hidden_dim_list, learning_rate_list, epochs_list = ensure_list(n_samples, hidden_dim,learning_rate, epochs)\n",
    "\n",
    "save_path_csv = \"results\"\n",
    "if not os.path.exists(save_path_csv):\n",
    "        os.makedirs(save_path_csv)\n",
    "\n",
    "# 결과를 저장할 DataFrame 생성\n",
    "results_df_train = pd.DataFrame(columns=['N_Samples', 'Hidden_Dim', 'Learning_Rate', 'Epochs', 'Data_Type', 'R_Squared', 'Mean_Abs_Rel_Residual', 'Max_Abs_Rel_Residual'])\n",
    "results_df_test = pd.DataFrame(columns=['N_Samples', 'Hidden_Dim', 'Learning_Rate', 'Epochs', 'Data_Type', 'R_Squared', 'Mean_Abs_Rel_Residual', 'Max_Abs_Rel_Residual'])\n",
    "\n",
    "for n_samples, hidden_dim, learning_rate, epochs in zip(n_samples_list, hidden_dim_list, learning_rate_list, epochs_list):\n",
    "    # 결과 저장 경로\n",
    "    save_path = f\"{save_path_csv}/samples_{n_samples}_hidden_{hidden_dim}_learning_rate_{learning_rate}\"\n",
    "    \n",
    "    # 디렉토리가 없으면 생성\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    print(f\"Training with n_samples={n_samples}, hidden_dim={hidden_dim}, learning_rate={learning_rate}, epochs={epochs}\")\n",
    "    # 최적의 모델 훈련\n",
    "    best_func, x_train, t_train, x_test, t_test, max_r_squared_model = train_ode_models(n_samples, hidden_dim,num_layers, learning_rate, epochs, save_path)\n",
    "    \n",
    "    # 훈련 데이터의 2D 그래프와 Actual vs Predicted Plot 저장\n",
    "    x_pred_train_best = odeint(best_func, x_train[0], t_train).squeeze()\n",
    "    save_2d_and_actual_vs_predicted(x_train, x_pred_train_best, 'train', hidden_dim, n_samples, epochs, save_path)\n",
    "    \n",
    "    # 반지름 잔차 컨투어\n",
    "    save_2d_radius_difference_contour_fixed(x_train, x_pred_train_best, 'train', hidden_dim, n_samples, epochs, save_path)\n",
    "    # 잔차 분포표\n",
    "    plot_radius_deviation_histogram(x_train, x_pred_train_best, 'train', hidden_dim, n_samples, epochs, save_path)\n",
    "    \n",
    "    # 테스트 데이터의 2D 그래프와 Actual vs Predicted Plot 저장\n",
    "    x_pred_test_best = odeint(best_func, x_test[0], t_test).squeeze()\n",
    "    save_2d_and_actual_vs_predicted(x_test, x_pred_test_best, 'test', hidden_dim, n_samples, epochs, save_path)\n",
    "    \n",
    "    # 수치 검증 결과를 CSV로 저장 (훈련 데이터)\n",
    "    r_squared_train, mean_abs_rel_residual_train, max_abs_rel_residual_train =return_numerical_validation(x_train, x_pred_train_best, 'train', hidden_dim, n_samples, epochs, save_path_csv)\n",
    "    \n",
    "    # 수치 검증 결과를 CSV로 저장 (테스트 데이터)\n",
    "    r_squared_test, mean_abs_rel_residual_test, max_abs_rel_residual_test =return_numerical_validation(x_test, x_pred_test_best, 'test', hidden_dim, n_samples, epochs, save_path_csv)\n",
    "    \n",
    "    # 결과 DataFrame에 추가 (훈련 데이터)\n",
    "    results_df_train.loc[len(results_df_train)] = [n_samples, hidden_dim, learning_rate, epochs, 'Train', r_squared_train, mean_abs_rel_residual_train.item(), max_abs_rel_residual_train.item()]\n",
    "\n",
    "    # 결과 DataFrame에 추가 (테스트 데이터)\n",
    "    results_df_test.loc[len(results_df_test)] = [n_samples, hidden_dim, learning_rate, epochs, 'Test', r_squared_test, mean_abs_rel_residual_test.item(), max_abs_rel_residual_test.item()]\n",
    "\n",
    "# 전체 결과를 CSV 파일로 저장\n",
    "results_df_train.to_csv(f\"{save_path_csv}/numerical_train.csv\", index=False)\n",
    "results_df_test.to_csv(f\"{save_path_csv}/numerical_test.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:06:03.104408700Z",
     "start_time": "2023-08-15T16:04:51.829557700Z"
    }
   },
   "id": "86084ccc4c2cb9a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
